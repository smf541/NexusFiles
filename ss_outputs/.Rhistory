print(posterior)
#prior
prior <- c(1, 1, 1)
#enter/compute likelihood
likelihood <- c(0, 2, 6)
#calculate unstandardised posterior
unstd.posterior <- prior*likelihood
#standardize posterior
posterior <- unstd.posterior/sum(unstd.posterior)
print(posterior)
#p_grid
p_grid <- seq(from=0, to=1, length.out=1000)
#prior
prior <- rep(1, 1000)
#enter/compute likelihood
likelihood <- dbinom(6, size=9, prob=p_grid)
#calculate unstandardised posterior
unstd.posterior <- prior*likelihood
#standardize posterior
posterior <- unstd.posterior/sum(unstd.posterior)
print(posterior)
samples <- sample(p_grid, prob=posterior, size=1e4, replace=TRUE)
plot(samples)
library(rethinking)
dens(samples)
sum(posterior[p_grid < 0.5])
sum(samples<0.5)/1e4
quantile(samples, 0.8)
PI(samples, prob=0.5)
# simulating observations from likelihood distribution
dbinom(0:2, size=2, prob=0.7)
# simulating observations from likelihood distribution
dbinom(0:2, size=4, prob=0.7)
# simulating observations from likelihood distribution
dbinom(0:4, size=4, prob=0.7)
# simulating observations from likelihood distribution
rbinom(1, size=2, prob=0.7)
# simulating observations from likelihood distribution
rbinom(10, size=2, prob=0.7)
dummy_w <- rbinom(1e5, size=2, prob=0.7)
table(dummy_w)/1e5
# simulating observations from likelihood distribution
dummy_w <- rbinom(1e5, size=9, prob=0.7)
simplehist(dummy_w, xlab="dummy water count")
library(rethinking)
simplehist(dummy_w, xlab="dummy water count")
# simulating observations from likelihood distribution
dummy_w <- rbinom(1e5, size=50, prob=0.7)
simplehist(dummy_w, xlab="dummy water count")
# simulating observations from likelihood distribution
dummy_w <- rbinom(1e5, size=100, prob=0.7)
simplehist(dummy_w, xlab="dummy water count")
# simulating observations from likelihood distribution
dummy_w <- rbinom(1e5, size=1000, prob=0.7)
simplehist(dummy_w, xlab="dummy water count")
# simulating observations from likelihood distribution
w <- rbinom(1e4, size=9, prob=0.6)
simplehist(w, xlab="dummy water count")
samples <- sample(p_grid, prob=posterior, size=1e4, replace=TRUE)
# simulating observations from likelihood distribution
w <- rbinom(1e4, size=9, prob=samples)
simplehist(w, xlab="dummy water count")
library(rethinking)
#p_grid
p_grid <- seq(from=0, to=1, length.out=1000)
#prior
prior <- rep(1, 1000)
#enter/compute likelihood
likelihood <- dbinom(6, size=9, prob=p_grid)
#calculate unstandardised posterior
unstd.posterior <- prior*likelihood
#standardize posterior
posterior <- unstd.posterior/sum(unstd.posterior)
set.seed(100)
samples <- sample(p_grid, prob=posterior, size=1e4, replace=TRUE)
PI(samples, prob=0.5)
#how much posterior probability lies below p=0.2?
sum(samples < 0.2)/1e4
simplehist(samples)
p_grid <- seq(from=0, to=1, length.out=1000)
#prior
prior <- rep(1, 1000)
#enter/compute likelihood
likelihood <- dbinom(6, size=9, prob=p_grid)
#calculate unstandardised posterior
unstd.posterior <- prior*likelihood
#standardize posterior
posterior <- unstd.posterior/sum(unstd.posterior)
set.seed(100)
samples <- sample(p_grid, prob=posterior, size=1e4, replace=TRUE)
simplehist(samples)
p_grid <- seq(from=0, to=1, length.out=1000)
#prior
prior <- rep(1, 1000)
#enter/compute likelihood
likelihood <- dbinom(6, size=9, prob=p_grid)
#calculate unstandardised posterior
unstd.posterior <- prior*likelihood
#standardize posterior
posterior <- unstd.posterior/sum(unstd.posterior)
samples <- sample(p_grid, prob=posterior, size=1e4, replace=TRUE)
simplehist(samples)
samples <- sample(p_grid, prob=posterior, size=1e4, replace=TRUE)
simplehist(samples)
plot(samples)
#how much posterior probability lies below p=0.2?
sum(samples < 0.2)/1e4
#how much posterior probability lies above p=0.8?
sum(samples>0.8)/1e4
#between p=0.2 and p=0.8?
sum(samples >=0.2, samples <= 0.8)/1e4
#between p=0.2 and p=0.8?
sum(samples >=0.2 & samples <= 0.8)/1e4
#20% of the posterior probability lies below which value of p?
quantile(samples, 0.2)
simplehist(samples)
hist(samples)
#20% of the posterior probability lies below which value of p?
quantile(samples, 0.8)
#which values of p contain the narrowest interval equal to 66% of PP?
HPDI(samples, 0.66)
#which values of p contain the narrowest interval equal to 66% of PP?
HPDI(samples, prob=0.66)
#which values of p contain 66% of PP, assuming equal PP below and above the interval?
PI(samples, prob=0.66)
#p_grid
p_grid <- seq(from=0, to=1, length.out=1000)
#prior
prior <- rep(1, 1000)
#enter/compute likelihood
likelihood <- dbinom(8, size=15, prob=p_grid)
#calculate unstandardised posterior
unstd.posterior <- prior*likelihood
#standardize posterior
posterior <- unstd.posterior/sum(unstd.posterior)
simplehist(posterior)
simplehist(p_grid, posterior)
samples <- sample(p_grid, prob=posterior, size=1e4, replace=TRUE)
hist(samples)
plot(posterior ~ p_grid, type="l")
samples <- sample(p_grid, prob=posterior, size=1e4, replace=TRUE)
HPDI(samples, 0.9)
dummy_3M3 <- rbinom(1e4, size=15, prob=samples)
simplehist(dummy_3M3)
mean(dummy_3M3 ==8)
dummy_3M3 <- rbinom(1e4, size=9, prob=samples)
simplehist(dummy_3M3)
mean(dummy_3M3 ==8)
mean(dummy_3M3 ==6)
#prior
prior <- ifelse(p_grid<0.5, 0, 1)
#enter/compute likelihood
likelihood <- dbinom(8, size=15, prob=p_grid)
#calculate unstandardised posterior
unstd.posterior <- prior*likelihood
#standardize posterior
posterior <- unstd.posterior/sum(unstd.posterior)
plot(posterior ~ p_grid, type="l")
samples <- sample(p_grid, prob=posterior, size=1e4, replace=TRUE)
HPDI(samples, 0.9)
dummy_3M3 <- rbinom(1e4, size=15, prob=samples)
mean(dummy_3M3 ==8)
dummy_3M3 <- rbinom(1e4, size=9, prob=samples)
mean(dummy_3M3 ==6)
# Ch 3 Hard exercises
library(rethinking)
# Ch 3 Hard exercises
library(rethinking)
data(homeworkch3)
p_grid <- seq( from=0, to=1, length.out=1000)
prior_b <- rep(1, 1000)
likelihood_b <- dbinom(111, size=200, prob=p_grid)
unstd.boys <- prior_b*likelihood_b
boys <- unstd.boys/sum(unstd.boys)
plot(boys ~p_grid, type="b")
#3H2
sample_boys <- sample(p_grid, prob=boys, size=1e4, replace=TRUE)
HPDI(sample_boys, 0.5)
HPDI(sample_boys, 0.89)
HPDI(sample_boys, 0.97)
#3H3
dummy_boys <- rbinom(1e4, size=200, prob=sample_boys)
dens(dummy_boys)
p_grid[which.max(posterior)]
dens(dummy_boys), adj=0.1
dens(dummy_boys, adj=0.1)
abline(v=111, col="pink")
#3H4
dummy_boys1 <- rbinom(1e4, size=100, prob=sample_boys)
dens(dummy_boys, adj=0.1)
dens(dummy_boys1, adj=0.1)
abline(v= sum(birth1), col="red")
#3H5
first.born.girl <- 100-sum(birth1)
dummy_second.born <- rbinom(1e4, size=first.born.girl, prob=sample_boys)
dens(dummy_second.born)
#3H5
boy.after.girl <- birth2[birth1==0]
dummy_second.born <- rbinom(1e4, size=bou.after.girl, prob=sample_boys)
dens(dummy_second.born)
dummy_second.born <- rbinom(1e4, size=boy.after.girl, prob=sample_boys)
dens(dummy_second.born)
dens(dummy_second.born, adj=0.1)
abline(v=sum(birth1), col="red")
dens(dummy_second.born, adj=0.1)
abline(v=sum(birth1), col="red")
abline(v=sum(boy.after.girl) col="red")
abline(v=sum(boy.after.girl), col="red")
boys.born.after.girls <- birth2[birth1 == 0]
posterior.predictive.distribution <- rbinom(n = trials, size = length(boys.born.after.girls), prob = sample_boys)
dens(posterior.predictive.distribution, adj = .1)
abline(v = sum(boys.born.after.girls), col = "red")
trials <- 1e4
boys.born.after.girls <- birth2[birth1 == 0]
posterior.predictive.distribution <- rbinom(n = trials, size = length(boys.born.after.girls), prob = sample_boys)
dens(posterior.predictive.distribution, adj = .1)
abline(v = sum(boys.born.after.girls), col = "red")
boy.after.girl <- birth2[birth1==0]
dummy_second.born <- rbinom(1e4, size=length(boy.after.girl), prob=sample_boys)
dens(dummy_second.born, adj=0.1)
abline(v=sum(boy.after.girl), col="red")
prod(1+runif(12,0,0.1))
growth <- replicate (10000, prod(1+runif(12,0,0.1)))
dens(growth, norm.comp = TRUE)
growth <- replicate (10000, prod(1+runif(12,0,0.5)))
dens(growth, norm.comp = TRUE)
growth <- replicate (10000, prod(1+runif(12,0,0.01)))
dens(growth, norm.comp = TRUE)
growth <- replicate (10000, log(prod(1+runif(12,0,0.5))))
dens(growth, norm.comp = TRUE)
data(Howell1)
d <- Howell1
library(rethinking)
data(Howell1)
d <- Howell1
str(d)
#filter out anyone younger than 18
d2 <- d[ d$age >= 18, ]
str(d2)
dens(d2$height)
curve(dnorm(x,178,20), from=100, to=250)
curve(dunif(x, 0, 50), from=-10, to=60)
#sampling the prior of mu and sigma
sample_mu <- rnorm(1e4, 178, 20)
sample_sigma <- runif(1e4, 0, 50)
prior_h <- rnorm(1e4, sample_mu, sample_sigma)
dens(prior_h)
#sampling the prior of mu and sigma
sample_mu <- rnorm(1e4, 178, 40)
sample_sigma <- runif(1e4, 0, 50)
prior_h <- rnorm(1e4, sample_mu, sample_sigma)
dens(prior_h)
#sampling the prior of mu and sigma
sample_mu <- rnorm(1e4, 178, 20)
sample_sigma <- runif(1e4, 0, 50)
prior_h <- rnorm(1e4, sample_mu, sample_sigma)
dens(prior_h)
#sampling the prior of mu and sigma
sample_mu <- rnorm(1e4, 160, 20)
sample_sigma <- runif(1e4, 0, 50)
prior_h <- rnorm(1e4, sample_mu, sample_sigma)
dens(prior_h)
mu.list <- seq(from=140, to=160, length.out=200)
sigma.list <- seq(from=4, to=9, length.out=200)
post <- expand.grid(mu=mu.list, sigma=sigma.list)
post$LL <- sapply(1:nrow(post), function(i) sum(dnorm(d2$height,
mean=post$mu[i],
sd=post$sigma[i],
log=TRUE)))
post$prod <- post$LL + dnorm(post$mu, 178, 20, TRUE) +
dunif(post$sigma, 0, 50, TRUE)
post$prob <- exp(post$prod - max(post$prod))
#plot posterior distribution
contour_xyz(post$mu, post$sigma, post$prob)
image_xyz(post$mu, post$sigma, post$prob)
sample.rows <- sample(1:nrow(post), size=1e4, replace=TRUE, psob=post$prob)
sample.mu <- post$mu[sample.rows]
sample.sigma <- post$sigma[sample.rows]
sample.rows <- sample(1:nrow(post), size=1e4, replace=TRUE, prob=post$prob)
sample.mu <- post$mu[sample.rows]
sample.sigma <- post$sigma[sample.rows]
plot(sample.mu, sample.sigma, cex=0.5, pch=16, col=col.alpha(rangi2,0.1))
plot(sample.mu, sample.sigma, cex=1, pch=16, col=col.alpha(rangi2,0.1))
install.packages("ssh")
#set current working directory
setwd("C:\\Users\\dxsb43\\GitHub\\NexusFiles\\ss_outputs")
#read in ss output file
df <- read.table("weev_unpart_ss.nex.ss", header=TRUE, skip=6)
df
#first check that aSplitX is < or == 0.1
if (df$aSplit0[40] > 0.1) {
print("Runs have not converged")
}
#check if any values in columns run1 - runn are positive
if (rowSums(df[,3:6]>0)>0) {
print("Positive log likelihood found")
}
#set current working directory
setwd("C:\\Users\\dxsb43\\GitHub\\NexusFiles\\ss_outputs")
#read in ss output file
df <- read.table("weev_unpart_ss.nex.ss", header=TRUE, skip=6)
df
#first check that aSplitX is < or == 0.1
if (df$aSplit0[40] > 0.1) {
print("Runs have not converged")
}
#check if any values in columns run1 - runn are positive
if (rowSums(df[,3:6]>0)<0) {
print("Positive log likelihood found")
}
#set current working directory
setwd("C:\\Users\\dxsb43\\GitHub\\NexusFiles\\ss_outputs")
#read in ss output file
df <- read.table("weev_unpart_ss.nex.ss", header=TRUE, skip=6)
df
#first check that aSplitX is < or == 0.1
if (df$aSplit0[40] > 0.1) {
print("Runs have not converged")
}
#check if any values in columns run1 - runn are positive
if (df[,3:6]>0) {
print("Positive log likelihood found")
}
#set current working directory
setwd("C:\\Users\\dxsb43\\GitHub\\NexusFiles\\ss_outputs")
#read in ss output file
df <- read.table("weev_unpart_ss.nex.ss", header=TRUE, skip=6)
df
#first check that aSplitX is < or == 0.1
if (df$aSplit0[40] > 0.1) {
print("Runs have not converged")
}
#check if any values in columns run1 - runn are positive
if (df[,3:6]<0) {
print("Positive log likelihood found")
}
#set current working directory
setwd("C:\\Users\\dxsb43\\GitHub\\NexusFiles\\ss_outputs")
#read in ss output file
df <- read.table("weev_unpart_ss.nex.ss", header=TRUE, skip=6)
df
#first check that aSplitX is < or == 0.1
if (df$aSplit0[40] > 0.1) {
print("Runs have not converged")
}
#check if any values in columns run1 - runn are positive
if (df[,3:6]>0) {
print("Positive log likelihood found")
}
if (sign(df[,3:6])>0) {
print("Positive log likelihood found")
}
class(df[,3])
obj(df[,3])
df[,3]
is.vector(df[,3])
if (sign(df[,3])<0) {
print("Positive log likelihood found")
}
sign(df[,3])
sign(df[,3:6])
if (c(0,1) %in% sign(df[,3:6])) {
print("Positive log likelihood found")
}
if (0:1 %in% sign(df[,3:6])) {
print("Positive log likelihood found")
}
if (0 %in% sign(df[,3:6])) {
print("Positive log likelihood found")
}
#check if any values in columns run1 - runn are positive
if (1 %in% sign(df[,3:6])) {
print("Positive log likelihood found")
}
#set current working directory
setwd("C:\\Users\\dxsb43\\GitHub\\NexusFiles\\ss_outputs")
#read in ss output file
df <- read.table("weev_unpart_ss.nex.ss", header=TRUE, skip=6)
df
#first check that aSplitX is < or == 0.1
if (df$aSplit0[40] > 0.1) {
print("Runs have not converged")
}
#check if any values in columns run1 - runn are positive
if (1 %in% sign(df[,3:6])) {
print("Positive log likelihood found")
}
sign(df[,3:6])
if (-1 %in% sign(df[,3:6])) {
print("Positive log likelihood found")
}
#first check that aSplitX is < or == 0.1
if (df$aSplit0[40] < 0.1) {
print("Runs have not converged")
}
if (colSums(sign(df[,3:6])) = 40 ) {
#check if any values in columns run1 - runn are positive
if (colSums(sign(df[,3:6])) == 40 ) {
print("Positive log likelihood found")
}
#check if any values in columns run1 - runn are positive
if (colSums(sign(df[,3])) == 40 ) {
print("Positive log likelihood found")
}
#check if any values in columns run1 - runn are positive
if (colSums(sign(df[,3:6])) == c(40,40,40,40) ) {
print("Positive log likelihood found")
}
-1 %in% sign(df[,3])
if (-1 %in% sign(df[,3:6]) == TRUE) {
print("Positive log likelihood found")
}
if (1 %in% sign(df[,3:6]) == TRUE) {
print("Positive log likelihood found")
}
#set current working directory
setwd("C:\\Users\\dxsb43\\GitHub\\NexusFiles\\ss_outputs")
#read in ss output file
df <- read.table("weev_unpart_ss.nex.ss", header=TRUE, skip=6)
df
#first check that aSplitX is < or == 0.1
if (df$aSplit0[40] < 0.1) {
print("Runs have not converged")
}
#check if any values in columns run1 - runn are positive
if (colSums(sign(df[,3:6])) == c(40,40,40,40) ) {
print("Positive log likelihood found")
}
sign(df[,3:6])
if (1 %in% sign(df[,3:6]) == TRUE) {
print("Positive log likelihood found")
}
-1 %in% sign(df[,3])
sign(df[,3:6])
if (1 %in% sign(df[,3:6]) == TRUE) {
print("Positive log likelihood found")
}
-1 %in% sign(df[,3])
1 %in% sign(df[,3])
if (-1 %in% sign(df[,3:6]) == TRUE) {
print("Positive log likelihood found")
}
if (any(sign(df[,3:6]) == -1) ) {
print("Positive log likelihood found")
}
if (any(sign(df[,3:6]) == 1) ) {
print("Positive log likelihood found")
}
if (any(sign(df[,3:6]) > -1)) {
print("Positive log likelihood found")
}
df2 <- cbind(c(1,2,3), c(4,5,6))
df2 <- cbind(c(1,2,3,4,5,6,7), c(4,5,6,7,8,9,10))
if (any(sign(df2[,3:6]) > -1)) {
print("Positive log likelihood found")
}
df2 <- cbind(c(1,2,3), c(4,5,6))
if (any(sign(df2[,2]) > -1)) {
print("Positive log likelihood found")
}
View(df2)
View(df)
View(df)
setwd("C:\\Users\\dxsb43\\GitHub\\NexusFiles\\ss_outputs")
df <- read.table("weev_unpart_ss.nex.ss", header=TRUE, skip=6)
check.ss <- function(x) {
if (x$aSplit0[40] < 0.1) {
print("Runs have not converged")
}
}
check.ss(df)
if (x$aSplit0[40] > -1) {
print("Runs have not converged")
}
check.ss <- function(x) {
if (x$aSplit0[40] > -1) {
print("Runs have not converged")
}
}
check.ss(df)
check.ss <- function(x) {
if (x$aSplit0[40] > -1) {
print("Runs have not converged")
}
else if (any(sign(df[,3:6]) > -1)) {
print("Positive log likelihood found")
}
}
check.ss(df)
print("All good!")
check.ss <- function(x) {
if (x$aSplit0[40] > -1) {
print("Runs have not converged")
}
else if (any(sign(df[,3:6]) > -1)) {
print("Positive log likelihood found")
}
else {
print("All good!")
}
}
check.ss(df)
check.ss(df)
sum.ln.ml <- function(x) {
apply(df[,3:6], 2, sum)
}
sum.ln.ml(df)
mean(sum.ln.ml(x))
mean.ln.ml <- function(x) {
mean(sum.ln.ml(x))
}
mean.ln.ml(df)
